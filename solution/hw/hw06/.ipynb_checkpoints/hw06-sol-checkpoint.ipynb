{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homework 6: Testing Hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading**: Textbook chapter [11](https://umass-data-science.github.io/190fwebsite/textbook/11/testing-hypotheses/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please complete this notebook by filling in the cells provided. Before you begin, execute the following cell to load the provided tests. Each time you start your server, you will need to execute this cell again to load the tests.\n",
    "\n",
    "Homework 6 is due **Friday, 11/2 at 11:59pm**. Start early so that you can come to office hours if you're stuck. Check the website for the office hours schedule. Late work will not be accepted as per the [policies](https://umass-data-science.github.io/190fwebsite/policies/) of this course. \n",
    "\n",
    "Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged. Refer to the policies page to learn more about how to learn cooperatively.\n",
    "\n",
    "For all problems that you must write our explanations and sentences for, you **must** provide your answer in the designated space. Moreover, throughout this homework and all future ones, please be sure to not re-assign variables throughout the notebook! For example, if you use `max_temperature` in your answer to one question, do not reassign it later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this cell; just run it. \n",
    "! pip install -U okpy\n",
    "\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "\n",
    "# These lines do some fancy plotting magic.\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('hw06.ok')\n",
    "_ = ok.auth(inline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Catching Cheaters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you are a casino owner, and your casino runs a very simple game of chance.  The dealer flips a coin.  The customer wins 9 dollars from the casino if it comes up heads and loses 10 dollars if it comes up tails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "**Question 1.** Assuming no one is cheating and the coin is fair, if a customer plays twice, what is the chance they make money?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "manual_grade": true,
    "manual_problem_id": "catching_cheaters_1"
   },
   "outputs": [],
   "source": [
    "p_winning_after_two_flips = 0.5 * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q1_1')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A certain customer plays the game 20 times and wins 13 of the bets.  You suspect that the customer is cheating!  That is, you think that their chance of winning is higher than the normal chance of winning.\n",
    "\n",
    "You decide to test your hunch using the outcomes of the 20 games you observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "**Question 2.** Define the null hypothesis and alternative hypothesis for this investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "for_assignment_type": "student",
    "manual_grade": true,
    "manual_problem_id": "catching_cheaters_2"
   },
   "source": [
    "**Null hypothesis:** The customer is not cheating and has an equal chance of winning provided the coin is fair.\n",
    "\n",
    "**Alternative hypothesis:** The customer is cheating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "**Question 3.** Given the outcome of 20 games, which of the following test statistics would be a reasonable choice for this hypothesis test? \n",
    "\n",
    "*Hint*: For a refresher on choosing test statistics, check out [Section 11.3 of the textbook](https://umass-data-science.github.io/190fwebsite/textbook/11/3/decisions-and-uncertainty/).\n",
    "\n",
    "1. Whether there is at least one win.\n",
    "1. Whether there is at least one loss.\n",
    "1. The number of wins.\n",
    "1. The number of wins minus the number of losses.\n",
    "1. The total variation distance between the probability distribution of a fair coin and the observed distribution of heads and tails.\n",
    "1. The total amount of money that the customer won.\n",
    "\n",
    "Assign `reasonable_test_statistics` to a **list** of numbers corresponding to these test statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reasonable_test_statistics = [3, 4, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q1_3')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "Suppose you decide to use the number of wins as your test statistic.\n",
    "\n",
    "**Question 4.** Write a function called `simulate` that simulates your test statistic.  It should take no arguments.  It should return the number of wins in 20 games simulated under the assumption that the result of each game is sampled from a fair coin (one that is equally likely to get heads or tails).\n",
    "\n",
    "*Hint*: You may find the [`sample_proportions`](https://umass-data-science.github.io/190fwebsite/textbook/11/1/assessing-models/) function to be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def simulate():\n",
    "#    return sample_proportions(20, [0.5, 0.5])[0] * 20\n",
    "\n",
    "def simulate():\n",
    "    model_prop = (0.5, 0.5)\n",
    "    sim = sample_proportions(20, model_prop)\n",
    "    return sim[0] * 20\n",
    "\n",
    "simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q1_4')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.** Using 10,000 trials, generate simulated values of the number of wins in 20 games. Assign `test_statistics_under_null` to an array that stores the result of each of these trials.\n",
    "\n",
    "*Hint*: Feel free to use the function you defined in Question 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "test_statistics_under_null = []\n",
    "repetitions = 10000\n",
    "\n",
    "for i in np.arange(repetitions):\n",
    "    test_statistics_under_null = np.append(test_statistics_under_null, simulate())\n",
    "\n",
    "test_statistics_under_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q1_5')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6.** Using the results from Question 5, generate a histogram of the empirical distribution of the number of wins in 20 games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "for_assignment_type": "student",
    "manual_grade": true,
    "manual_problem_id": "catching_cheaters_6"
   },
   "outputs": [],
   "source": [
    "x = Table().with_column('test', test_statistics_under_null)\n",
    "x.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "**Question 7.** Compute an empirical P-value for this test.\n",
    "\n",
    "*Hint:* Which values of our test statistic are in the direction of the alternative hypothesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = np.sum(test_statistics_under_null >= 10) / repetitions\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q1_7')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Landing a Spacecraft\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note: This problem describes something that's close to [a real story with a very exciting video](http://www.space.com/29119-spacex-reusable-rocket-landing-crash-video.html), but the details have been changed somewhat.)\n",
    "\n",
    "SpaceY, a company that builds and tests spacecraft, is testing a new reusable launch system.  Most spacecraft use a \"first stage\" rocket that propels a smaller payload craft away from Earth, then falls back to the ground and crashes.  SpaceY's new system is designed to land safely at a landing pad at a certain location, ready for later reuse.  If it doesn't land in the right location, it crashes, and the (very expensive) vehicle is destroyed.\n",
    "\n",
    "SpaceY has tested this system over 1000 times.  Ordinarily, the vehicle doesn't land exactly on the landing pad.  For example, a gust of wind might move it by a few meters just before it lands.  It's reasonable to think of these small errors as random.  That is, the landing locations are drawn from some distribution over locations on the surface of Earth, centered around the landing pad.\n",
    "\n",
    "Run the next cell to see a plot of those locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinary_landing_spots = Table.read_table(\"ordinary_landing_spots.csv\")\n",
    "ordinary_landing_spots.scatter(\"x\", label=\"Landing locations\")\n",
    "plt.scatter(0, 0, c=\"w\", s=1000, marker=\"*\", label=\"Landing pad\")\n",
    "plt.legend(scatterpoints=1, bbox_to_anchor=(1.6, .5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During one test, the vehicle lands far away from the landing pad and crashes.  SpaceY investigators suspect there was a problem unique to this landing, a problem that wasn't part of the ordinary pattern of variation in landing locations.  They think a software error in the guidance system caused the craft to incorrectly attempt to land at a spot other than the landing pad.  The guidance system engineers think there was nothing out of the ordinary in this landing, and that there was no special problem with the guidance system.\n",
    "\n",
    "Run the cell below to see a plot of the 1100 ordinary landings and the crash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landing_spot = make_array(80.59, 30.91)\n",
    "ordinary_landing_spots.scatter(\"x\", label=\"Other landings\")\n",
    "plt.scatter(0, 0, c=\"w\", s=1000, marker=\"*\", label=\"Landing pad\")\n",
    "plt.scatter(landing_spot.item(0), landing_spot.item(1), marker=\"*\", c=\"r\", s=1000, label=\"Crash site\")\n",
    "plt.legend(scatterpoints=1, bbox_to_anchor=(1.6, .5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "**Question 1.** Suppose we'd like to use hypothesis testing to shed light on this question.  We've written down an alternative hypothesis below.  What is a reasonable null hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "for_assignment_type": "student",
    "manual_grade": true,
    "manual_problem_id": "landing_1"
   },
   "source": [
    "**Null hypothesis:** The landing was ordinary and the location was drawn from the same distribution of other landings. \n",
    "\n",
    "**Alternative hypothesis:** This landing was special; its location was a draw from some other distribution, not the distribution from which the other 1100 landing locations were drawn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "**Question 2.** What's a good test statistic for this hypothesis test? \n",
    "\n",
    "*Hint:* A test statistic can be almost anything, but a *good* test statistic varies informatively depending on whether the null is true. So for this example, we might think about a test statistic that would be small if the null is true, and large otherwise. If we want to compare landings, we might want to see *how far* each landing is from some *reference point*, so we can compare all landings from the same vantage point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "for_assignment_type": "student",
    "manual_grade": true,
    "manual_problem_id": "landing_2"
   },
   "source": [
    "**Test statistic:** Distance from the landing pad. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "**Question 3.** Write a function called `landing_test_statistic`.  It should take two arguments: an \"x\" location and a \"y\" location (both numbers).  It should return the value of your test statistic for a landing at those coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "manual_grade": true,
    "manual_problem_id": "landing_3"
   },
   "outputs": [],
   "source": [
    "def landing_test_statistic(x_coordinate, y_coordinate):\n",
    "    return(np.sqrt(x_coordinate ** 2 + y_coordinate ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "**Question 4.** The next three cells compute a P-value using your test statistic. Describe the test procedure in words. Is there a simulation involved? If so, what is being simulated? If not, why not? Where are we getting the data from? What kind of calculations are being performed? How are we calculating our p-value? \n",
    "\n",
    "*Hint:* Think about what a [simulation](https://umass-data-science.github.io/190fwebsite/textbook/09/3/simulation/) actually consists of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_test_stat = landing_test_statistic(\n",
    "    landing_spot.item(0),\n",
    "    landing_spot.item(1))\n",
    "\n",
    "observed_test_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_stats = make_array()\n",
    "repetitions = ordinary_landing_spots.num_rows\n",
    "\n",
    "for i in np.arange(repetitions):\n",
    "    null_stat = landing_test_statistic(\n",
    "        ordinary_landing_spots.column('x').item(i),\n",
    "        ordinary_landing_spots.column('y').item(i))\n",
    "    null_stats = np.append(null_stats, null_stat)\n",
    "    \n",
    "null_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = np.count_nonzero(null_stats >= observed_test_stat) / len(null_stats)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "for_assignment_type": "student",
    "manual_problem_id": "landing_4"
   },
   "source": [
    "Calculating the observed test statistic, then calculate the test statistic for all landing locations, then calculate p_value based on the past landing locations and the new landing location. No simulation was performed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing Dice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Students in a Data Science class want to figure out whether a six-sided die is fair or not. On a fair die, each face of the die appears with chance 1/6 on each roll, regardless of the results of other rolls.  Otherwise, a die is called unfair.  We can describe a die by the probability of landing on each face.  This table describes an example of a die that is unfairly weighted toward 1:\n",
    "\n",
    "|Face|Probability|\n",
    "|--|\n",
    "|1|.5|\n",
    "|2|.1|\n",
    "|3|.1|\n",
    "|4|.1|\n",
    "|5|.1|\n",
    "|6|.1|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "**Question 1.** Define a null hypothesis and an alternative hypothesis to test whether a six-sided die is fair or not. \n",
    "\n",
    "*Hint:* Remember that an unfair die is one for which each face does not have an equal chance of appearing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "for_assignment_type": "student",
    "manual_grade": true,
    "manual_problem_id": "testing_dice_1"
   },
   "source": [
    "**Null hypothesis:** The die is fair with equal probability of 1/6 for each side. \n",
    "\n",
    "**Alternative hypothesis:** The die is unfair.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide to test the die by rolling it 5 times. The proportions of the 6 faces in these 5 rolls are stored in a table with 6 rows.  For example, here is the table we'd make if the die rolls ended up being 1, 2, 3, 3, and 5:\n",
    "\n",
    "|Face|Proportion|\n",
    "|--|\n",
    "|1|.2|\n",
    "|2|.2|\n",
    "|3|.4|\n",
    "|4|.0|\n",
    "|5|.2|\n",
    "|6|.0|\n",
    "\n",
    "The function `mystery_test_statistic`, defined below, takes a single table like this as its argument and returns a number (which we will use as a test statistic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: We've intentionally used obscurantist function and\n",
    "# variable names to avoid giving away answers.  It's rarely\n",
    "# a good idea to use names like \"x\" in your code.\n",
    "\n",
    "def mystery_test_statistic(sample):\n",
    "    x = sum(sample.column(\"Face\")*sample.column(\"Proportion\"))\n",
    "    y = np.mean(np.arange(1, 6+1, 1))\n",
    "    return abs(x - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "**Question 2.** Describe in English what the test statistic is.  Is it equivalent to the total variation distance between the observed face distribution and the fair die distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "manual_grade": true,
    "manual_problem_id": "testing_dice_2"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `simulate_observations_and_test` takes as its argument a table describing the probability distribution of a die.  It simulates one set of 5 rolls of that die, then tests the null hypothesis about that die using our test statistic function above.  It returns `False` if it *rejects* the null hypothesis about the die, and `True` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The probability distribution table for a fair die:\n",
    "fair_die = Table().with_columns(\n",
    "        \"Face\", np.arange(1, 6+1),\n",
    "        \"Probability\", [1/6, 1/6, 1/6, 1/6, 1/6, 1/6])\n",
    "\n",
    "def simulate_observations_and_test(actual_die):\n",
    "    \"\"\"Simulates die rolls from actual_die and tests the hypothesis that the die is fair.\n",
    "    \n",
    "    Returns False if that hypothesis is rejected, and True otherwise.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sample_size = 5\n",
    "    p_value_cutoff = .2\n",
    "    num_simulations = 250\n",
    "    \n",
    "    # Compute the observed value of the test statistic.\n",
    "    observation_set = sample_proportions(sample_size, actual_die.column(\"Probability\"))\n",
    "    observation_props_table = Table().with_column('Face', actual_die.column('Face'), 'Proportion', observation_set)\n",
    "    observed_statistic = mystery_test_statistic(observation_props_table)\n",
    "    \n",
    "    # Simulate the test statistic repeatedly to get an \n",
    "    # approximation to the probability distribution of \n",
    "    # the test statistic, as predicted by the model in \n",
    "    # the null hypothesis. Store the simulated values \n",
    "    # of the test statistic in an array.\n",
    "    simulated_statistics = make_array()\n",
    "    for _ in np.arange(num_simulations):\n",
    "        one_observation_set_under_null = sample_proportions(sample_size, fair_die.column(\"Probability\"))\n",
    "        simulated_props_table = Table().with_column('Face', fair_die.column('Face'), 'Proportion', one_observation_set_under_null)\n",
    "        simulated_statistic = mystery_test_statistic(simulated_props_table)\n",
    "        simulated_statistics = np.append(simulated_statistics, simulated_statistic)\n",
    "        \n",
    "    # Compute the P-value\n",
    "    p_value = np.count_nonzero(simulated_statistics >= observed_statistic) / num_simulations\n",
    "    \n",
    "    # If the P-value is below the cutoff, reject the \n",
    "    # null hypothesis and return False. Otherwise, \n",
    "    # return True.\n",
    "    return p_value >= p_value_cutoff\n",
    "\n",
    "# Calling the function to simulate a test of a fair die:\n",
    "simulate_observations_and_test(fair_die)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "**Question 3.** Use your knowledge of hypothesis tests and interpretation of the code above to compute the probability that `simulate_observations_and_test` returns `False` when its argument is `fair_die` (which is defined above the function).  You can call the function a few times to see what it does, but **don't** perform a simulation to compute this probability.  Use your knowledge of hypothesis tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_of_false = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q3_3')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "**Question 4.** Why is your answer to Question 3 the correct probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "manual_grade": true,
    "manual_problem_id": "testing_dice_4"
   },
   "source": [
    "p_value_cutoff = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "**Question 5.** Simulate the process of running `simulation_observations_and_test` 300 times. Assign `test_results` to an array that stores the result of each of these trials.\n",
    "\n",
    "**Note:** This will be a little slow. 300 repetitions of the simulation should require a minute or so of computation, and should suffice to get an answer that's roughly correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "num_test_simulations = 300\n",
    "test_results = make_array()\n",
    "for i in np.arange(num_test_simulations):\n",
    "    result = simulate_observations_and_test(fair_die)\n",
    "    test_results = np.append(test_results, result)\n",
    "\n",
    "# Don't change the following line.\n",
    "test_results.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q3_5')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "**Question 6.** Verify your answer to Question 3 by computing an approximate probability that `simulation_observations_and_test` returns `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approximate_probability_of_false = 1 - (np.count_nonzero(test_results) / num_test_simulations)\n",
    "approximate_probability_of_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q3_6')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "**Question 7.** From the perspective of someone who wants to know the truth about the die, is it good or bad for the function to return `False` when its argument is `fair_die`? Why is it good or bad?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "manual_grade": true,
    "manual_problem_id": "testing_dice_7"
   },
   "source": [
    "Bad. False means the null hypothesis, that the die is fair is rejected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Submission\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Once you're finished, select \"Save and Checkpoint\" in the File menu and then execute the `submit` cell below. The result will contain a link that you can use to check that your assignment has been submitted successfully. If you submit more than once before the deadline, we will only grade your final submission. If you mistakenly submit the wrong one, you can head to [okpy.org](https://okpy.org/) and flag the correct version. To do so, go to the website, click on this assignment, and find the version you would like to have graded. There should be an option to flag that submission for grading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
